{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch Normalization - Effect of Batch Size",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTLiAHRQ0VgNOrxZfOvkgg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/DLshots/blob/master/Batch_Normalization_Effect_of_Batch_Size.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKzu9hbgqw2x",
        "colab_type": "text"
      },
      "source": [
        "# Setups, Installations and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT_P8aSjO-ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "1cfc61fd-9e79-4f16-8e5f-5225b5b0a209"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 27 16:10:47 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAZBTFNQq0ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-APP7-6C5uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 666\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pr3HrMxq8SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmVkQbw_q_07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "f67dfa14-cb66-45aa-bd03-c5ca725cf6de"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "API Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Ln8W0Aru8X",
        "colab_type": "text"
      },
      "source": [
        "# Download and Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMFYLweasySz",
        "colab_type": "text"
      },
      "source": [
        "#### CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Posjlu7lDJBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6667215c-447e-4e24-cbc5-e3b8ac7fafa4"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcM1SXdiGVf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASS_NAMES = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDLO83axDOzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "9528e0c9-c15f-44ec-ab9d-1c6cfe97a7c2"
      },
      "source": [
        "print('Shape of x_train: ', x_train.shape)\n",
        "print('Shape of y_train: ', y_train.shape)\n",
        "print('Shape of x_test: ', x_test.shape)\n",
        "print('Shape of y_test: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train:  (50000, 32, 32, 3)\n",
            "Shape of y_train:  (50000, 1)\n",
            "Shape of x_test:  (10000, 32, 32, 3)\n",
            "Shape of y_test:  (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5j_ZoeQqq9pc"
      },
      "source": [
        "# Dataloader Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo6RDCQQlVhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "IMG_SHAPE = 32\n",
        "CHANNELS = 3\n",
        "NUM_CLASSES = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjkVhSbgeizK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(image, label):\n",
        "  image = image/255\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkxDAl8pv5pJ",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OcwOQYgIoyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch):\n",
        "  if epoch < 7:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * tf.math.exp(0.1 * (7 - epoch))\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adFPkCE5uAvo",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxoW4LzZmpDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ModelBN():\n",
        "  inputs = keras.layers.Input(shape=(IMG_SHAPE, IMG_SHAPE, CHANNELS))\n",
        "\n",
        "  x = keras.layers.Conv2D(filters=32,\n",
        "                          kernel_size=(3,3),\n",
        "                          strides=(1,1),\n",
        "                          padding='valid')(inputs)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(filters=32, \n",
        "                          kernel_size=(3,3),\n",
        "                          strides=(1,1),\n",
        "                          padding='valid')(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "\n",
        "  x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(filters=32, \n",
        "                          kernel_size=(3,3),\n",
        "                          strides=(1,1),\n",
        "                          padding='valid')(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "\n",
        "  x = keras.layers.Conv2D(filters=32, \n",
        "                          kernel_size=(3,3),\n",
        "                          strides=(1,1),\n",
        "                          padding='valid')(x)\n",
        "  x = keras.layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "\n",
        "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "  x = keras.layers.Dense(128, activation='relu')(x)\n",
        "  x = keras.layers.Dense(32, activation='relu')(x)\n",
        "  \n",
        "  outputs = keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "  return keras.models.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSmoIktbZO62",
        "colab_type": "text"
      },
      "source": [
        "# Sweep Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kOA4UVgZs-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    # Initialize wandb with a sample project name\n",
        "    wandb.init()\n",
        "    \n",
        "    # Specify the hyperparameter to be tuned along with\n",
        "    # an initial value\n",
        "    configs = {\n",
        "        'batch_size': 8\n",
        "    }\n",
        "\n",
        "    # Specify the other hyperparameters to the configuration\n",
        "    config = wandb.config\n",
        "    config.epochs = 25\n",
        "\n",
        "    # Add the config item (layers) to wandb\n",
        "    if wandb.run:\n",
        "        wandb.config.update({k: v for k, v in configs.items() if k not in dict(wandb.config.user_items())})\n",
        "        configs = dict(wandb.config.user_items())\n",
        "\n",
        "    # Prepare data loader\n",
        "    trainloader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    testloader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "    trainloader = (\n",
        "        trainloader\n",
        "        .shuffle(1024)\n",
        "        .map(preprocess_image, num_parallel_calls=AUTO)\n",
        "        .batch(wandb.config.batch_size)\n",
        "        .prefetch(AUTO)\n",
        "    )\n",
        "\n",
        "    testloader = (\n",
        "        testloader\n",
        "        .map(preprocess_image, num_parallel_calls=AUTO)\n",
        "        .batch(wandb.config.batch_size)\n",
        "        .prefetch(AUTO)\n",
        "    )\n",
        "  \n",
        "    # Iniialize model\n",
        "    keras.backend.clear_session()\n",
        "    model = ModelBN()\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile('adam', 'sparse_categorical_crossentropy', metrics=['acc'])\n",
        "    \n",
        "    # Train the model\n",
        "    _ = model.fit(trainloader,\n",
        "                  epochs=config.epochs,\n",
        "                  validation_data=testloader,\n",
        "                  callbacks=[WandbCallback(),\n",
        "                            lr_callback])\n",
        "\n",
        "    # Evaluate    \n",
        "    loss, accuracy = model.evaluate(testloader, callbacks=[WandbCallback()])\n",
        "    print('Test Error Rate: ', round((1-accuracy)*100, 2))\n",
        "    wandb.log({'Test Error Rate': round((1-accuracy)*100, 2)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI_JI2HBZs10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sweep_config = {\n",
        "  'method': 'grid',\n",
        "  'parameters': {\n",
        "      'batch_size': {\n",
        "          'values': [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
        "      }\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWpCLwGqncdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9a3ba1b8-9f15-47b2-ebf8-eb9f2053365f"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity='authors', project=\"seo\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 2w36r6w1\n",
            "Sweep URL: https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goZ3Z7A8nbpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f829ca41-9bab-4e9f-d33d-26f56bad52ec"
      },
      "source": [
        "wandb.agent(sweep_id, function=train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wandb: Agent Starting Run: 5ldej7vv with config:\n",
            "\tbatch_size: 8\n",
            "wandb: Agent Started Run: 5ldej7vv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/5ldej7vv\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/5ldej7vv</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 1.5241 - acc: 0.4424 - val_loss: 1.3479 - val_acc: 0.5208 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "6250/6250 [==============================] - 61s 10ms/step - loss: 1.1806 - acc: 0.5802 - val_loss: 1.1342 - val_acc: 0.5957 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 1.0599 - acc: 0.6259 - val_loss: 1.1041 - val_acc: 0.6045 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.9850 - acc: 0.6536 - val_loss: 1.0082 - val_acc: 0.6455 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.9345 - acc: 0.6737 - val_loss: 1.0407 - val_acc: 0.6305 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.8873 - acc: 0.6919 - val_loss: 0.8685 - val_acc: 0.6966 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "6250/6250 [==============================] - 61s 10ms/step - loss: 0.8591 - acc: 0.7033 - val_loss: 0.8554 - val_acc: 0.6930 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "6250/6250 [==============================] - 61s 10ms/step - loss: 0.8287 - acc: 0.7132 - val_loss: 0.8230 - val_acc: 0.7155 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.7902 - acc: 0.7276 - val_loss: 0.7752 - val_acc: 0.7350 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.7611 - acc: 0.7388 - val_loss: 0.8290 - val_acc: 0.7167 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.7303 - acc: 0.7487 - val_loss: 0.8748 - val_acc: 0.7023 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "6250/6250 [==============================] - 61s 10ms/step - loss: 0.7114 - acc: 0.7557 - val_loss: 0.7645 - val_acc: 0.7332 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.6897 - acc: 0.7616 - val_loss: 0.6426 - val_acc: 0.7751 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.6679 - acc: 0.7704 - val_loss: 0.7179 - val_acc: 0.7552 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.6517 - acc: 0.7754 - val_loss: 0.6605 - val_acc: 0.7684 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.6375 - acc: 0.7804 - val_loss: 0.6512 - val_acc: 0.7720 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.6217 - acc: 0.7859 - val_loss: 0.6680 - val_acc: 0.7727 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "6250/6250 [==============================] - 59s 10ms/step - loss: 0.6110 - acc: 0.7891 - val_loss: 0.6753 - val_acc: 0.7675 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "6250/6250 [==============================] - 59s 9ms/step - loss: 0.5940 - acc: 0.7934 - val_loss: 0.6779 - val_acc: 0.7718 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "6250/6250 [==============================] - 59s 9ms/step - loss: 0.5868 - acc: 0.7979 - val_loss: 0.6152 - val_acc: 0.7882 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "6250/6250 [==============================] - 59s 9ms/step - loss: 0.5813 - acc: 0.7980 - val_loss: 0.6367 - val_acc: 0.7838 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "6250/6250 [==============================] - 59s 9ms/step - loss: 0.5668 - acc: 0.8036 - val_loss: 0.6197 - val_acc: 0.7856 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "6250/6250 [==============================] - 60s 10ms/step - loss: 0.5661 - acc: 0.8056 - val_loss: 0.6233 - val_acc: 0.7842 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "6250/6250 [==============================] - 59s 9ms/step - loss: 0.5581 - acc: 0.8079 - val_loss: 0.6449 - val_acc: 0.7794 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "6250/6250 [==============================] - 59s 9ms/step - loss: 0.5543 - acc: 0.8096 - val_loss: 0.6106 - val_acc: 0.7890 - lr: 1.8268e-04\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6106 - acc: 0.7890\n",
            "Test Error Rate:  21.1\n",
            "wandb: Agent Finished Run: 5ldej7vv \n",
            "\n",
            "wandb: Agent Starting Run: a4qhogfb with config:\n",
            "\tbatch_size: 16\n",
            "wandb: Agent Started Run: a4qhogfb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/a4qhogfb\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/a4qhogfb</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 1.4305 - acc: 0.4758 - val_loss: 1.3895 - val_acc: 0.5138 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 1.1032 - acc: 0.6076 - val_loss: 1.2194 - val_acc: 0.5721 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.9928 - acc: 0.6479 - val_loss: 1.0806 - val_acc: 0.6268 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.9131 - acc: 0.6785 - val_loss: 1.0378 - val_acc: 0.6233 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.8634 - acc: 0.6958 - val_loss: 0.8996 - val_acc: 0.6862 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.8148 - acc: 0.7154 - val_loss: 0.9295 - val_acc: 0.6774 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.7866 - acc: 0.7255 - val_loss: 0.9005 - val_acc: 0.6959 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.7581 - acc: 0.7351 - val_loss: 0.9732 - val_acc: 0.6613 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.7204 - acc: 0.7479 - val_loss: 0.9731 - val_acc: 0.6632 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.6957 - acc: 0.7599 - val_loss: 0.8225 - val_acc: 0.7210 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.6648 - acc: 0.7679 - val_loss: 0.8963 - val_acc: 0.7000 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "3125/3125 [==============================] - 31s 10ms/step - loss: 0.6412 - acc: 0.7774 - val_loss: 0.8087 - val_acc: 0.7236 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.6196 - acc: 0.7840 - val_loss: 0.6708 - val_acc: 0.7711 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.6015 - acc: 0.7908 - val_loss: 0.7589 - val_acc: 0.7448 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.5869 - acc: 0.7968 - val_loss: 0.7004 - val_acc: 0.7605 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.5732 - acc: 0.8004 - val_loss: 0.6636 - val_acc: 0.7746 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "3125/3125 [==============================] - 31s 10ms/step - loss: 0.5558 - acc: 0.8063 - val_loss: 0.6839 - val_acc: 0.7666 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.5423 - acc: 0.8113 - val_loss: 0.7021 - val_acc: 0.7610 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.5315 - acc: 0.8138 - val_loss: 0.6858 - val_acc: 0.7657 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.5233 - acc: 0.8177 - val_loss: 0.6238 - val_acc: 0.7877 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.5136 - acc: 0.8203 - val_loss: 0.6095 - val_acc: 0.7921 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.5034 - acc: 0.8241 - val_loss: 0.6170 - val_acc: 0.7899 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.4968 - acc: 0.8256 - val_loss: 0.6039 - val_acc: 0.7932 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.4906 - acc: 0.8298 - val_loss: 0.6106 - val_acc: 0.7904 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "3125/3125 [==============================] - 32s 10ms/step - loss: 0.4861 - acc: 0.8310 - val_loss: 0.5998 - val_acc: 0.7953 - lr: 1.8268e-04\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.5998 - acc: 0.7953\n",
            "Test Error Rate:  20.47\n",
            "wandb: Agent Finished Run: a4qhogfb \n",
            "\n",
            "wandb: Agent Starting Run: t9jzzb73 with config:\n",
            "\tbatch_size: 32\n",
            "wandb: Agent Started Run: t9jzzb73\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/t9jzzb73\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/t9jzzb73</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 1.4034 - acc: 0.4846 - val_loss: 1.5492 - val_acc: 0.4620 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0572 - acc: 0.6209 - val_loss: 1.0813 - val_acc: 0.6179 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9325 - acc: 0.6686 - val_loss: 1.3147 - val_acc: 0.5732 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.8569 - acc: 0.6957 - val_loss: 1.1410 - val_acc: 0.5991 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8050 - acc: 0.7155 - val_loss: 0.8785 - val_acc: 0.6883 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7622 - acc: 0.7313 - val_loss: 0.8742 - val_acc: 0.6886 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7374 - acc: 0.7420 - val_loss: 0.9052 - val_acc: 0.6838 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7095 - acc: 0.7522 - val_loss: 1.0404 - val_acc: 0.6447 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6731 - acc: 0.7645 - val_loss: 0.8938 - val_acc: 0.6973 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6489 - acc: 0.7732 - val_loss: 0.9041 - val_acc: 0.6968 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.6181 - acc: 0.7834 - val_loss: 0.6969 - val_acc: 0.7590 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.5975 - acc: 0.7936 - val_loss: 0.7053 - val_acc: 0.7541 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.5739 - acc: 0.8001 - val_loss: 0.6868 - val_acc: 0.7587 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5553 - acc: 0.8064 - val_loss: 0.7344 - val_acc: 0.7490 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.5394 - acc: 0.8118 - val_loss: 0.6655 - val_acc: 0.7693 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5230 - acc: 0.8155 - val_loss: 0.6835 - val_acc: 0.7637 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.5069 - acc: 0.8235 - val_loss: 0.7085 - val_acc: 0.7571 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.4946 - acc: 0.8265 - val_loss: 0.6576 - val_acc: 0.7816 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.4829 - acc: 0.8314 - val_loss: 0.6429 - val_acc: 0.7824 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.4759 - acc: 0.8352 - val_loss: 0.6570 - val_acc: 0.7769 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.4666 - acc: 0.8372 - val_loss: 0.6421 - val_acc: 0.7863 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4550 - acc: 0.8419 - val_loss: 0.6642 - val_acc: 0.7800 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4470 - acc: 0.8456 - val_loss: 0.6239 - val_acc: 0.7898 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4417 - acc: 0.8472 - val_loss: 0.6384 - val_acc: 0.7869 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4377 - acc: 0.8467 - val_loss: 0.6442 - val_acc: 0.7851 - lr: 1.8268e-04\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6442 - acc: 0.7851\n",
            "Test Error Rate:  21.49\n",
            "wandb: Agent Finished Run: t9jzzb73 \n",
            "\n",
            "wandb: Agent Starting Run: dz4ums9h with config:\n",
            "\tbatch_size: 64\n",
            "wandb: Agent Started Run: dz4ums9h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/dz4ums9h\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/dz4ums9h</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4114 - acc: 0.4823 - val_loss: 1.4319 - val_acc: 0.4996 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.0576 - acc: 0.6231 - val_loss: 1.2672 - val_acc: 0.5477 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.9343 - acc: 0.6676 - val_loss: 1.3124 - val_acc: 0.5604 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.8519 - acc: 0.6969 - val_loss: 1.0187 - val_acc: 0.6379 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.7966 - acc: 0.7185 - val_loss: 1.0565 - val_acc: 0.6351 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.7543 - acc: 0.7357 - val_loss: 1.1117 - val_acc: 0.6301 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.7152 - acc: 0.7479 - val_loss: 0.9636 - val_acc: 0.6653 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.6938 - acc: 0.7568 - val_loss: 0.9242 - val_acc: 0.6721 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.6604 - acc: 0.7677 - val_loss: 0.9563 - val_acc: 0.6781 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.6285 - acc: 0.7783 - val_loss: 1.0074 - val_acc: 0.6644 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.6067 - acc: 0.7878 - val_loss: 0.8627 - val_acc: 0.7074 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5852 - acc: 0.7970 - val_loss: 0.9068 - val_acc: 0.6917 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5653 - acc: 0.8024 - val_loss: 0.7825 - val_acc: 0.7348 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5462 - acc: 0.8102 - val_loss: 0.7699 - val_acc: 0.7392 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5315 - acc: 0.8148 - val_loss: 0.7498 - val_acc: 0.7463 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5161 - acc: 0.8196 - val_loss: 0.6913 - val_acc: 0.7631 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5041 - acc: 0.8244 - val_loss: 0.6980 - val_acc: 0.7654 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4940 - acc: 0.8280 - val_loss: 0.6898 - val_acc: 0.7679 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4800 - acc: 0.8327 - val_loss: 0.7390 - val_acc: 0.7555 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4744 - acc: 0.8352 - val_loss: 0.6913 - val_acc: 0.7688 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4652 - acc: 0.8382 - val_loss: 0.6573 - val_acc: 0.7775 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4532 - acc: 0.8421 - val_loss: 0.6664 - val_acc: 0.7763 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4442 - acc: 0.8458 - val_loss: 0.6537 - val_acc: 0.7803 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4401 - acc: 0.8471 - val_loss: 0.6567 - val_acc: 0.7762 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4363 - acc: 0.8488 - val_loss: 0.6796 - val_acc: 0.7724 - lr: 1.8268e-04\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.6796 - acc: 0.7724\n",
            "Test Error Rate:  22.76\n",
            "wandb: Agent Finished Run: dz4ums9h \n",
            "\n",
            "wandb: Agent Starting Run: vrnu0yc6 with config:\n",
            "\tbatch_size: 128\n",
            "wandb: Agent Started Run: vrnu0yc6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/vrnu0yc6\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/vrnu0yc6</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 1.4758 - acc: 0.4559 - val_loss: 2.3184 - val_acc: 0.2454 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 1.0941 - acc: 0.6059 - val_loss: 1.2032 - val_acc: 0.5652 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.9662 - acc: 0.6555 - val_loss: 1.2041 - val_acc: 0.5704 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.8776 - acc: 0.6877 - val_loss: 0.9846 - val_acc: 0.6455 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.8186 - acc: 0.7077 - val_loss: 1.0533 - val_acc: 0.6249 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.7757 - acc: 0.7245 - val_loss: 1.1818 - val_acc: 0.6127 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.7343 - acc: 0.7401 - val_loss: 0.9419 - val_acc: 0.6695 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.7081 - acc: 0.7516 - val_loss: 1.0262 - val_acc: 0.6533 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.6734 - acc: 0.7626 - val_loss: 1.0627 - val_acc: 0.6455 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.6429 - acc: 0.7737 - val_loss: 0.9747 - val_acc: 0.6722 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.6219 - acc: 0.7825 - val_loss: 0.9354 - val_acc: 0.6828 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.6004 - acc: 0.7878 - val_loss: 0.8343 - val_acc: 0.7074 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.5809 - acc: 0.7966 - val_loss: 0.8105 - val_acc: 0.7179 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.5631 - acc: 0.8043 - val_loss: 0.7821 - val_acc: 0.7280 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.5518 - acc: 0.8078 - val_loss: 0.9200 - val_acc: 0.6914 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 0.5344 - acc: 0.8139 - val_loss: 0.7974 - val_acc: 0.7210 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.5251 - acc: 0.8168 - val_loss: 0.7716 - val_acc: 0.7334 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.5132 - acc: 0.8208 - val_loss: 0.7275 - val_acc: 0.7508 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.5005 - acc: 0.8256 - val_loss: 0.7677 - val_acc: 0.7365 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.4939 - acc: 0.8274 - val_loss: 0.7637 - val_acc: 0.7360 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.4854 - acc: 0.8315 - val_loss: 0.6947 - val_acc: 0.7604 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.4744 - acc: 0.8348 - val_loss: 0.7573 - val_acc: 0.7437 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.4671 - acc: 0.8369 - val_loss: 0.7271 - val_acc: 0.7542 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.4622 - acc: 0.8380 - val_loss: 0.7427 - val_acc: 0.7454 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.4576 - acc: 0.8402 - val_loss: 0.7124 - val_acc: 0.7535 - lr: 1.8268e-04\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.7124 - acc: 0.7535\n",
            "Test Error Rate:  24.65\n",
            "wandb: Agent Finished Run: vrnu0yc6 \n",
            "\n",
            "wandb: Agent Starting Run: n5fz93qb with config:\n",
            "\tbatch_size: 256\n",
            "wandb: Agent Started Run: n5fz93qb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/n5fz93qb\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/n5fz93qb</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 1.5796 - acc: 0.4213 - val_loss: 3.3767 - val_acc: 0.1001 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "196/196 [==============================] - 8s 42ms/step - loss: 1.1833 - acc: 0.5736 - val_loss: 2.2974 - val_acc: 0.2736 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "196/196 [==============================] - 8s 42ms/step - loss: 1.0366 - acc: 0.6299 - val_loss: 1.9642 - val_acc: 0.3944 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "196/196 [==============================] - 8s 42ms/step - loss: 0.9458 - acc: 0.6641 - val_loss: 1.3164 - val_acc: 0.5328 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "196/196 [==============================] - 8s 42ms/step - loss: 0.8792 - acc: 0.6891 - val_loss: 1.1608 - val_acc: 0.5839 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "196/196 [==============================] - 8s 42ms/step - loss: 0.8337 - acc: 0.7065 - val_loss: 1.0265 - val_acc: 0.6395 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.7889 - acc: 0.7231 - val_loss: 0.9377 - val_acc: 0.6703 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.7557 - acc: 0.7355 - val_loss: 0.9481 - val_acc: 0.6685 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.7207 - acc: 0.7488 - val_loss: 1.0398 - val_acc: 0.6439 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.6876 - acc: 0.7597 - val_loss: 0.9549 - val_acc: 0.6628 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.6601 - acc: 0.7700 - val_loss: 1.0460 - val_acc: 0.6527 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.6436 - acc: 0.7751 - val_loss: 0.8966 - val_acc: 0.6848 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.6233 - acc: 0.7824 - val_loss: 0.7956 - val_acc: 0.7231 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.6070 - acc: 0.7873 - val_loss: 0.8485 - val_acc: 0.7088 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.5936 - acc: 0.7944 - val_loss: 0.8808 - val_acc: 0.6973 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.5766 - acc: 0.8007 - val_loss: 0.8687 - val_acc: 0.7006 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.5681 - acc: 0.8020 - val_loss: 0.8045 - val_acc: 0.7251 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.5580 - acc: 0.8074 - val_loss: 0.8163 - val_acc: 0.7179 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.5442 - acc: 0.8119 - val_loss: 0.8070 - val_acc: 0.7278 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.5381 - acc: 0.8133 - val_loss: 0.8013 - val_acc: 0.7242 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.5298 - acc: 0.8173 - val_loss: 0.7193 - val_acc: 0.7525 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.5226 - acc: 0.8199 - val_loss: 0.7640 - val_acc: 0.7410 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.5144 - acc: 0.8233 - val_loss: 0.7582 - val_acc: 0.7429 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "196/196 [==============================] - 8s 41ms/step - loss: 0.5074 - acc: 0.8250 - val_loss: 0.7430 - val_acc: 0.7466 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "196/196 [==============================] - 8s 40ms/step - loss: 0.5031 - acc: 0.8266 - val_loss: 0.7199 - val_acc: 0.7509 - lr: 1.8268e-04\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 0.7199 - acc: 0.7509\n",
            "Test Error Rate:  24.91\n",
            "wandb: Agent Finished Run: n5fz93qb \n",
            "\n",
            "wandb: Agent Starting Run: yebummgk with config:\n",
            "\tbatch_size: 512\n",
            "wandb: Agent Started Run: yebummgk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/yebummgk\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/yebummgk</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "98/98 [==============================] - 8s 80ms/step - loss: 1.7253 - acc: 0.3741 - val_loss: 3.1914 - val_acc: 0.0997 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 1.2796 - acc: 0.5346 - val_loss: 3.7289 - val_acc: 0.0999 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 1.1252 - acc: 0.5952 - val_loss: 3.3402 - val_acc: 0.1131 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 7s 73ms/step - loss: 1.0284 - acc: 0.6341 - val_loss: 2.7371 - val_acc: 0.1960 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 7s 73ms/step - loss: 0.9574 - acc: 0.6597 - val_loss: 1.8590 - val_acc: 0.3776 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.9065 - acc: 0.6792 - val_loss: 1.3288 - val_acc: 0.5209 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.8657 - acc: 0.6948 - val_loss: 1.2610 - val_acc: 0.5682 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 0.8286 - acc: 0.7083 - val_loss: 1.5002 - val_acc: 0.5056 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.7872 - acc: 0.7247 - val_loss: 1.1171 - val_acc: 0.6112 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 0.7586 - acc: 0.7327 - val_loss: 1.2527 - val_acc: 0.5815 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.7390 - acc: 0.7419 - val_loss: 1.0264 - val_acc: 0.6357 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 0.7106 - acc: 0.7530 - val_loss: 1.3445 - val_acc: 0.5512 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.6925 - acc: 0.7589 - val_loss: 0.9471 - val_acc: 0.6582 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 0.6764 - acc: 0.7651 - val_loss: 0.9917 - val_acc: 0.6481 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 0.6602 - acc: 0.7710 - val_loss: 0.9844 - val_acc: 0.6562 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.6472 - acc: 0.7748 - val_loss: 0.8641 - val_acc: 0.6928 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 0.6375 - acc: 0.7774 - val_loss: 0.8871 - val_acc: 0.6891 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 0.6260 - acc: 0.7827 - val_loss: 0.9002 - val_acc: 0.6886 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 7s 73ms/step - loss: 0.6148 - acc: 0.7861 - val_loss: 0.8076 - val_acc: 0.7139 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.6072 - acc: 0.7894 - val_loss: 0.9236 - val_acc: 0.6785 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.6005 - acc: 0.7931 - val_loss: 0.8134 - val_acc: 0.7109 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.5930 - acc: 0.7945 - val_loss: 0.8255 - val_acc: 0.7107 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.5859 - acc: 0.7961 - val_loss: 0.7957 - val_acc: 0.7215 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 0.5799 - acc: 0.7990 - val_loss: 0.8027 - val_acc: 0.7132 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 7s 72ms/step - loss: 0.5762 - acc: 0.8001 - val_loss: 0.7588 - val_acc: 0.7326 - lr: 1.8268e-04\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 0.7588 - acc: 0.7326\n",
            "Test Error Rate:  26.74\n",
            "wandb: Agent Finished Run: yebummgk \n",
            "\n",
            "wandb: Agent Starting Run: rblpv9qe with config:\n",
            "\tbatch_size: 1024\n",
            "wandb: Agent Started Run: rblpv9qe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/rblpv9qe\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/rblpv9qe</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "49/49 [==============================] - 8s 156ms/step - loss: 1.9228 - acc: 0.3088 - val_loss: 2.5299 - val_acc: 0.1520 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 1.4202 - acc: 0.4793 - val_loss: 3.2365 - val_acc: 0.1032 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 1.2421 - acc: 0.5512 - val_loss: 3.7989 - val_acc: 0.1019 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 1.1242 - acc: 0.5964 - val_loss: 4.3472 - val_acc: 0.1214 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 1.0461 - acc: 0.6267 - val_loss: 4.5544 - val_acc: 0.1271 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.9892 - acc: 0.6469 - val_loss: 4.1410 - val_acc: 0.1414 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.9380 - acc: 0.6676 - val_loss: 4.0370 - val_acc: 0.1554 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "49/49 [==============================] - 6s 132ms/step - loss: 0.9101 - acc: 0.6774 - val_loss: 3.1050 - val_acc: 0.2086 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.8724 - acc: 0.6902 - val_loss: 2.5563 - val_acc: 0.2858 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.8477 - acc: 0.7007 - val_loss: 2.0068 - val_acc: 0.3733 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.8214 - acc: 0.7092 - val_loss: 1.6206 - val_acc: 0.4574 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.7987 - acc: 0.7173 - val_loss: 1.4259 - val_acc: 0.5065 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "49/49 [==============================] - 7s 136ms/step - loss: 0.7824 - acc: 0.7231 - val_loss: 1.3587 - val_acc: 0.5422 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.7648 - acc: 0.7299 - val_loss: 1.1436 - val_acc: 0.5997 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.7529 - acc: 0.7331 - val_loss: 0.9876 - val_acc: 0.6499 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.7425 - acc: 0.7385 - val_loss: 1.0070 - val_acc: 0.6451 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.7302 - acc: 0.7432 - val_loss: 0.9462 - val_acc: 0.6616 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "49/49 [==============================] - 6s 133ms/step - loss: 0.7222 - acc: 0.7458 - val_loss: 0.9500 - val_acc: 0.6582 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.7145 - acc: 0.7490 - val_loss: 0.8513 - val_acc: 0.6954 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.7044 - acc: 0.7529 - val_loss: 0.8323 - val_acc: 0.7016 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.6974 - acc: 0.7552 - val_loss: 0.8267 - val_acc: 0.7032 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.6905 - acc: 0.7565 - val_loss: 0.8185 - val_acc: 0.7073 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "49/49 [==============================] - 7s 134ms/step - loss: 0.6849 - acc: 0.7598 - val_loss: 0.8153 - val_acc: 0.7078 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "49/49 [==============================] - 7s 135ms/step - loss: 0.6786 - acc: 0.7609 - val_loss: 0.7995 - val_acc: 0.7139 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "49/49 [==============================] - 7s 133ms/step - loss: 0.6741 - acc: 0.7621 - val_loss: 0.8010 - val_acc: 0.7127 - lr: 1.8268e-04\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 0.8010 - acc: 0.7127\n",
            "Test Error Rate:  28.73\n",
            "wandb: Agent Finished Run: rblpv9qe \n",
            "\n",
            "wandb: Agent Starting Run: 0m0p3ath with config:\n",
            "\tbatch_size: 2048\n",
            "wandb: Agent Started Run: 0m0p3ath\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/seo\" target=\"_blank\">https://app.wandb.ai/authors/seo</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/authors/seo/sweeps/2w36r6w1\" target=\"_blank\">https://app.wandb.ai/authors/seo/sweeps/2w36r6w1</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/authors/seo/runs/0m0p3ath\" target=\"_blank\">https://app.wandb.ai/authors/seo/runs/0m0p3ath</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "25/25 [==============================] - 7s 298ms/step - loss: 2.1034 - acc: 0.2620 - val_loss: 2.2987 - val_acc: 0.1086 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 1.6825 - acc: 0.3767 - val_loss: 2.5897 - val_acc: 0.1332 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 1.4315 - acc: 0.4742 - val_loss: 2.8739 - val_acc: 0.1003 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 1.3028 - acc: 0.5281 - val_loss: 3.2928 - val_acc: 0.1000 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 1.2145 - acc: 0.5635 - val_loss: 3.5515 - val_acc: 0.1003 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 1.1451 - acc: 0.5912 - val_loss: 3.7018 - val_acc: 0.1045 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 1.0893 - acc: 0.6099 - val_loss: 3.7768 - val_acc: 0.1244 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 1.0482 - acc: 0.6255 - val_loss: 3.7406 - val_acc: 0.1313 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 1.0039 - acc: 0.6421 - val_loss: 3.6672 - val_acc: 0.1270 - lr: 9.0484e-04\n",
            "Epoch 10/25\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.9775 - acc: 0.6508 - val_loss: 3.6703 - val_acc: 0.1412 - lr: 8.1873e-04\n",
            "Epoch 11/25\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.9542 - acc: 0.6606 - val_loss: 3.4626 - val_acc: 0.1691 - lr: 7.4082e-04\n",
            "Epoch 12/25\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.9319 - acc: 0.6689 - val_loss: 3.4173 - val_acc: 0.1769 - lr: 6.7032e-04\n",
            "Epoch 13/25\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.9089 - acc: 0.6775 - val_loss: 3.2985 - val_acc: 0.1907 - lr: 6.0653e-04\n",
            "Epoch 14/25\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.8935 - acc: 0.6827 - val_loss: 3.0640 - val_acc: 0.2112 - lr: 5.4881e-04\n",
            "Epoch 15/25\n",
            "25/25 [==============================] - 6s 249ms/step - loss: 0.8800 - acc: 0.6888 - val_loss: 2.9015 - val_acc: 0.2352 - lr: 4.9659e-04\n",
            "Epoch 16/25\n",
            "25/25 [==============================] - 6s 247ms/step - loss: 0.8684 - acc: 0.6926 - val_loss: 2.7094 - val_acc: 0.2541 - lr: 4.4933e-04\n",
            "Epoch 17/25\n",
            "25/25 [==============================] - 6s 248ms/step - loss: 0.8592 - acc: 0.6954 - val_loss: 2.4452 - val_acc: 0.2902 - lr: 4.0657e-04\n",
            "Epoch 18/25\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.8498 - acc: 0.6995 - val_loss: 2.1178 - val_acc: 0.3353 - lr: 3.6788e-04\n",
            "Epoch 19/25\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.8393 - acc: 0.7037 - val_loss: 1.8463 - val_acc: 0.3875 - lr: 3.3287e-04\n",
            "Epoch 20/25\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.8322 - acc: 0.7061 - val_loss: 1.5976 - val_acc: 0.4437 - lr: 3.0119e-04\n",
            "Epoch 21/25\n",
            "25/25 [==============================] - 6s 255ms/step - loss: 0.8259 - acc: 0.7080 - val_loss: 1.3886 - val_acc: 0.5033 - lr: 2.7253e-04\n",
            "Epoch 22/25\n",
            "25/25 [==============================] - 6s 250ms/step - loss: 0.8212 - acc: 0.7097 - val_loss: 1.2087 - val_acc: 0.5632 - lr: 2.4660e-04\n",
            "Epoch 23/25\n",
            "25/25 [==============================] - 6s 252ms/step - loss: 0.8179 - acc: 0.7110 - val_loss: 1.1126 - val_acc: 0.5943 - lr: 2.2313e-04\n",
            "Epoch 24/25\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.8133 - acc: 0.7130 - val_loss: 1.0465 - val_acc: 0.6229 - lr: 2.0190e-04\n",
            "Epoch 25/25\n",
            "25/25 [==============================] - 6s 251ms/step - loss: 0.8091 - acc: 0.7143 - val_loss: 0.9909 - val_acc: 0.6419 - lr: 1.8268e-04\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.9909 - acc: 0.6419\n",
            "Test Error Rate:  35.81\n",
            "wandb: Agent Finished Run: 0m0p3ath \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}